{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62889358-f712-4c6c-94eb-19e4063cc4df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "725c8749-132d-47c0-89bd-3de1b90e9ec1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "current_version = spark.sql(\"DESCRIBE HISTORY db_workspace.my_schema.revenues_per_day\").selectExpr(\"max(version)\").collect()[0][0]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"actors\", StringType(), True),\n",
    "    StructField(\"imdbRating\", StringType(), True),\n",
    "    StructField(\"imdbVotes\", StringType(), True),\n",
    "])\n",
    "\n",
    "@F.udf(schema)\n",
    "def from_url(title):\n",
    "    api_url = f\"https://www.omdbapi.com/?t={title}&apikey=b2715e56\"\n",
    "    response = requests.get(api_url)\n",
    "    movie_data = response.json()\n",
    "    data1 = movie_data.get('Actors', None)\n",
    "    data2 = movie_data.get('imdbRating', None)\n",
    "    data3 = movie_data.get('imdbVotes', None)\n",
    "    return (data1, data2, data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9cc753c-553d-4169-8504-42ebbef0b319",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read\n",
    "        .option('readChangeData', 'true')\n",
    "        .option(\"startingVersion\", current_version)\n",
    "        .table('db_workspace.my_schema.revenues_per_day')\n",
    "        .drop('id')\n",
    "        .withColumn('download_date', F.current_date())\n",
    "        .withColumn('from_url', from_url('title'))\n",
    ")\n",
    "\n",
    "df.write.mode('overwrite').saveAsTable('db_workspace.my_schema.temp')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "url_requests",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
